{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7ac943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting langchain==0.0.284 (from -r requirements.txt (line 1))\n",
      "  Using cached langchain-0.0.284-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting python-dotenv==1.0.0 (from -r requirements.txt (line 2))\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting streamlit==1.22.0 (from -r requirements.txt (line 3))\n",
      "  Using cached streamlit-1.22.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tiktoken==0.4.0 (from -r requirements.txt (line 4))\n",
      "  Using cached tiktoken-0.4.0.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.55.2 Requires-Python <3.5\n",
      "ERROR: Could not find a version that satisfies the requirement faiss-cpu==1.7.4 (from versions: 1.8.0, 1.8.0.post1, 1.9.0, 1.9.0.post1, 1.10.0, 1.11.0, 1.11.0.post1, 1.12.0, 1.13.0, 1.13.1)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for faiss-cpu==1.7.4\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7626cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: huggingface_hub in d:\\pytho3\\lib\\site-packages (0.36.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in d:\\pytho3\\lib\\site-packages (from langchain-huggingface) (1.1.1)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in d:\\pytho3\\lib\\site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: filelock in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.4.56)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\pytho3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\pytho3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\pytho3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\pytho3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\pytho3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\pytho3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (4.7.0)\n",
      "Requirement already satisfied: certifi in d:\\pytho3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\pytho3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\pytho3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\pytho3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pytho3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\pytho3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pytho3\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pytho3\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: colorama in d:\\pytho3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\pytho3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.3.1)\n",
      "Downloading langchain_huggingface-1.1.0-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: langchain-huggingface\n",
      "Successfully installed langchain-huggingface-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-huggingface huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173e4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"E:\\\\AI-Buildathon\\\\.env\")\n",
    "api_key = os.getenv(\"GOOGLE_GENAI_API_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86979275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7, api_key=api_key)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c36bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\pytho3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_pdf_documents(file_path):\n",
    "    loader= DirectoryLoader(\n",
    "        file_path,\n",
    "        glob=\"**/*.pdf\",\n",
    "        loader_cls=PyPDFLoader,\n",
    "    )\n",
    "    documents=loader.load()\n",
    "    return documents\n",
    "\n",
    "document=load_pdf_documents(\"E:\\\\AI-Buildathon\\\\data\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49764986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in document:\n",
    "    doc.metadata.update({\n",
    "        \"source\": \"WHO\",\n",
    "        \"category\": \"disease\",\n",
    "        \"region\": \"Bangladesh\",\n",
    "        \"language\": \"en\",\n",
    "        \"confidence_level\": \"primary\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2532b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 20271\n"
     ]
    }
   ],
   "source": [
    "def text_splitter(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "    )\n",
    "    text_chunk = text_splitter.split_documents(document)\n",
    "    return text_chunk\n",
    "\n",
    "text_chunk= text_splitter(document)\n",
    "print(f\"Number of Chunks: {len(text_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d82e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eae6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"E:\\\\AI-Buildathon\\\\.env\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869d1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index = pc.Index(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db5fd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docstore = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunk,\n",
    "    embedding=embedding_model,\n",
    "    index_name=\"test\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d55003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch= PineconeVectorStore.from_existing_index(\n",
    "    embedding=embedding_model,\n",
    "    index_name=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d7161fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ba17805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import (create_stuff_documents_chain)\n",
    "\n",
    "system_prompt=(\n",
    "    \"You are MaBondhu AI, a clinical assistant for maternal health. \"\n",
    "        \"Provide safe, evidence-based, concise guidance. Use the following pieces of retrieved context to answer the question at the end. \"\n",
    "        \"Language: {language}.\\n\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1) If this is potentially life-threatening, say 'EMERGENCY' and recommend immediate referral.\\n\"\n",
    "        \"2) If unsure, recommend human-in-the-loop evaluation and list needed vitals/tests.\\n\"\n",
    "        \"3) Include 1â€“2 specific, actionable next steps (e.g., 'go to nearest clinic', 'take iron supplement 60mg').\\n\"\n",
    "        \"4) Provide concise Bangla/English text depending on language.\\n\\n\"\n",
    "        \"5) If you don't know the answer, say 'Sorry, I don't know about it'.\\n\\n\"\n",
    "        \"Answer now in clear {language} with citations (e.g., [WHO Section 3]).\"\n",
    "        \"\\n\\n\"\n",
    "        \"Context:\\n{context}\\n\\n\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d1cee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_chain = create_stuff_documents_chain(llm,prompt=prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answering_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "402ffb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the birth of your first child, focus on these key aspects:\n",
      "\n",
      "1.  **Lead your baby's care:** Take charge of your baby's care, following the advice of doctors and midwives/birth attendants, and ensuring it works for your family. Never underestimate your opinion and ask all the questions you need to [Context 1, 2].\n",
      "2.  **Involve family:** Involve other family members in your baby's care and support system [Context 1, 2].\n",
      "3.  **Prioritize your wellbeing:** Seek information on lifestyle, working, and wellbeing to help you have a balanced and joyful experience [Context 3].\n",
      "\n",
      "**Next Steps:**\n",
      "*   Continue to consult with your doctors and midwives for personalized advice regarding your and your baby's health.\n",
      "*   Actively communicate with family members to establish a supportive environment for your new family.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inp=input(\"Enter your question: \")\n",
    "response = rag_chain.invoke({\n",
    "    \"input\": inp,\n",
    "    \"language\": \"English\"\n",
    "})\n",
    "\n",
    "print(response['answer']) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
