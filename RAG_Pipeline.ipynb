{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7ac943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting langchain==0.0.284 (from -r requirements.txt (line 1))\n",
      "  Using cached langchain-0.0.284-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting python-dotenv==1.0.0 (from -r requirements.txt (line 2))\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting streamlit==1.22.0 (from -r requirements.txt (line 3))\n",
      "  Using cached streamlit-1.22.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tiktoken==0.4.0 (from -r requirements.txt (line 4))\n",
      "  Using cached tiktoken-0.4.0.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.55.2 Requires-Python <3.5\n",
      "ERROR: Could not find a version that satisfies the requirement faiss-cpu==1.7.4 (from versions: 1.8.0, 1.8.0.post1, 1.9.0, 1.9.0.post1, 1.10.0, 1.11.0, 1.11.0.post1, 1.12.0, 1.13.0, 1.13.1)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for faiss-cpu==1.7.4\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7626cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: huggingface_hub in d:\\pytho3\\lib\\site-packages (0.36.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in d:\\pytho3\\lib\\site-packages (from langchain-huggingface) (1.1.1)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in d:\\pytho3\\lib\\site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: filelock in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\pytho3\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.4.56)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\pytho3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\pytho3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\pytho3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\pytho3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\pytho3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\pytho3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\pytho3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (4.7.0)\n",
      "Requirement already satisfied: certifi in d:\\pytho3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\pytho3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\pytho3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\pytho3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pytho3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\pytho3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pytho3\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pytho3\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: colorama in d:\\pytho3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\pytho3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.3.1)\n",
      "Downloading langchain_huggingface-1.1.0-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: langchain-huggingface\n",
      "Successfully installed langchain-huggingface-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-huggingface huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "173e4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"E:\\\\AI-Buildathon\\\\.env\")\n",
    "api_key = os.getenv(\"GOOGLE_GENAI_API_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86979275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7, api_key=api_key)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81c36bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=PyPDFLoader(\"E:\\\\AI-Buildathon\\\\WHO.pdf\")\n",
    "document= loader.load()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2532b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 857\n"
     ]
    }
   ],
   "source": [
    "def text_splitter(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "    text_chunk = text_splitter.split_documents(document)\n",
    "    return text_chunk\n",
    "\n",
    "text_chunk= text_splitter(document)\n",
    "print(f\"Number of Chunks: {len(text_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d82e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\pytho3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1115e2ab5b4e475892cbaa116edb7231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pytho3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\acer\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe66b34687a4be395335aae0dba2481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4db1f3d1be3449ba6349de8b9a7f73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289f40c5b69d495e8291e77571391d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ee14b0e9de4a2ba7a580be8d5e1334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792796ae7f19419eb9291a5c34880e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e1d7cfb26e48ee831506ddd545a360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71caca6aa8af4a338db5cc62b82097dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27acb6894d99411dbd18ca57137016c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9f8ad1f0d84751ad0f9b5ea516dca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e689e1027214bc0af8d3bdb9cc452a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1eae6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"E:\\\\AI-Buildathon\\\\.env\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "869d1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index = pc.Index(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dccc73ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\pytho3\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"langchain-pinecone\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db5fd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docstore = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunk,\n",
    "    embedding=embedding_model,\n",
    "    index_name=\"test\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d55003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch= PineconeVectorStore.from_existing_index(\n",
    "    embedding=embedding_model,\n",
    "    index_name=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d7161fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d373e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d34bfc67-b2ba-4fa8-8f00-098185e168ac', metadata={'author': 'ALLSOPP, Caroline E.', 'creationdate': '2025-02-25T13:49:54-05:00', 'creator': 'Adobe InDesign 14.0 (Macintosh)', 'moddate': '2025-05-20T09:21:28+00:00', 'page': 22, 'page_label': '23', 'producer': 'Adobe PDF Library 15.0', 'source': 'E:\\\\AI-Buildathon\\\\WHO.pdf', 'total_pages': 208, 'trapped': '/False'}, page_content='Context-specific recommendation - Research  \\nGroup antenatal care provided by qualified health-care professionals may be offered as an alternative \\nto individual antenatal care for pregnant women in the context of rigorous research, depending on \\na woman’s preferences and provided that the infrastructure and resources for delivery of group \\nantenatal care are available.\\xa0\\n ● With the group ANC model, the first visit for all pregnant women is an individual visit. Then at subsequent \\nvisits, the usual individual pregnancy health assessment, held in a private examination area, is integrated \\ninto a group ANC session, with facilitated educational activities and peer support.\\n ● Health-care facilities need to be seeing sufficient numbers of pregnant women, as allocation to groups is \\nideally performed according to gestational age.\\n ● Health-care providers need to have appropriate facilities to deal with group sessions, including access to'),\n",
       " Document(id='ba788b63-4c1d-4d2d-8b1d-55c3e522769e', metadata={'author': 'ALLSOPP, Caroline E.', 'creationdate': '2025-02-25T13:49:54-05:00', 'creator': 'Adobe InDesign 14.0 (Macintosh)', 'moddate': '2025-05-20T09:21:28+00:00', 'page': 22, 'page_label': '23', 'producer': 'Adobe PDF Library 15.0', 'source': 'E:\\\\AI-Buildathon\\\\WHO.pdf', 'total_pages': 208, 'trapped': '/False'}, page_content='Context-specific recommendation - Research  \\nGroup antenatal care provided by qualified health-care professionals may be offered as an alternative \\nto individual antenatal care for pregnant women in the context of rigorous research, depending on \\na woman’s preferences and provided that the infrastructure and resources for delivery of group \\nantenatal care are available.\\xa0\\n ● With the group ANC model, the first visit for all pregnant women is an individual visit. Then at subsequent \\nvisits, the usual individual pregnancy health assessment, held in a private examination area, is integrated \\ninto a group ANC session, with facilitated educational activities and peer support.\\n ● Health-care facilities need to be seeing sufficient numbers of pregnant women, as allocation to groups is \\nideally performed according to gestational age.\\n ● Health-care providers need to have appropriate facilities to deal with group sessions, including access to'),\n",
       " Document(id='ca66b921-2882-49d6-a49e-82d72ec53804', metadata={'author': 'ALLSOPP, Caroline E.', 'creationdate': '2025-02-25T13:49:54-05:00', 'creator': 'Adobe InDesign 14.0 (Macintosh)', 'moddate': '2025-05-20T09:21:28+00:00', 'page': 23, 'page_label': '24', 'producer': 'Adobe PDF Library 15.0', 'source': 'E:\\\\AI-Buildathon\\\\WHO.pdf', 'total_pages': 208, 'trapped': '/False'}, page_content='home visits are recommended to improve antenatal care utilization and perinatal health outcomes, \\nparticularly in rural settings with low access to health services.\\xa0\\n ● The GDG agreed that the extent to which these packages improve communication and support for \\npregnant women is not clear.\\n ● As a stand-alone intervention, the evidence does not support the use of antenatal home visits by lay health \\nworkers during pregnancy to improve ANC utilization health outcomes. While the quality and effectiveness \\nof communication during home visits, and the extent to which they increase support for women, is not \\nclear, antenatal home visits may be helpful in ensuring continuity of care across the antenatal, intrapartum \\nand postnatal periods and in promoting other healthy behaviour.\\n ● Stakeholders need to be clear that antenatal home visits by lay health workers do not replace ANC visits.\\n ● Stakeholders should implement health system strengthening interventions alongside these community-')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Antenatal Care?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ba17805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import (create_stuff_documents_chain)\n",
    "\n",
    "system_prompt=(\n",
    "    \"You are MaBondhu AI, a clinical assistant for maternal health. \"\n",
    "        \"Provide safe, evidence-based, concise guidance. Use the following pieces of retrieved context to answer the question at the end. \"\n",
    "        \"Language: {language}.\\n\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1) If this is potentially life-threatening, say 'EMERGENCY' and recommend immediate referral.\\n\"\n",
    "        \"2) If unsure, recommend human-in-the-loop evaluation and list needed vitals/tests.\\n\"\n",
    "        \"3) Include 1–2 specific, actionable next steps (e.g., 'go to nearest clinic', 'take iron supplement 60mg').\\n\"\n",
    "        \"4) Provide concise Bangla/English text depending on language.\\n\\n\"\n",
    "        \"5) If you don't know the answer, say 'Sorry, I don't know about it'.\\n\\n\"\n",
    "        \"Answer now in clear {language} with citations (e.g., [WHO Section 3]).\"\n",
    "        \"\\n\\n\"\n",
    "        \"Context:\\n{context}\\n\\n\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0d1cee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_chain = create_stuff_documents_chain(llm,prompt=prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answering_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ffb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, I don't know about it.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\n",
    "    \"input\": \"What are common diseases for a mother?\",\n",
    "    \"language\": \"English\"\n",
    "})\n",
    "\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
